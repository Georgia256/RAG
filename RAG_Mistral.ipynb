{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6a827997067416e84c5b798322d30cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79051322fd6c4ed98ebc0497d2cb12bf",
              "IPY_MODEL_a8b7454b99304e8093d25b85ce480f2b",
              "IPY_MODEL_6e16c29d053d4c2195d5303f85336101"
            ],
            "layout": "IPY_MODEL_1153df1c0a024464bbf1fa898bad171c"
          }
        },
        "79051322fd6c4ed98ebc0497d2cb12bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6d0af4c0eda47deacea6cf42441a3d6",
            "placeholder": "​",
            "style": "IPY_MODEL_7ee03dca708f4c05b70031d4a401eb4e",
            "value": "Parsing nodes: 100%"
          }
        },
        "a8b7454b99304e8093d25b85ce480f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bbc68f78dc740c7a5ddc2dfb707839f",
            "max": 3623,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a782496d1210484a8c631cafe12c1574",
            "value": 3623
          }
        },
        "6e16c29d053d4c2195d5303f85336101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987098d8472b4932968af544b21918d1",
            "placeholder": "​",
            "style": "IPY_MODEL_8027d8d135924145893ff391c3d8aba2",
            "value": " 3623/3623 [00:04&lt;00:00, 926.35it/s]"
          }
        },
        "1153df1c0a024464bbf1fa898bad171c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d0af4c0eda47deacea6cf42441a3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ee03dca708f4c05b70031d4a401eb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bbc68f78dc740c7a5ddc2dfb707839f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a782496d1210484a8c631cafe12c1574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "987098d8472b4932968af544b21918d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8027d8d135924145893ff391c3d8aba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "caa17dc1f5b54fe59b1364b222668f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b5f377de16d44509926894aca7dd347",
              "IPY_MODEL_298aaaa48ebe422c9f5b03a3a262d4f9",
              "IPY_MODEL_85043ebd9a394ec6bac2d350574cd6c8"
            ],
            "layout": "IPY_MODEL_d07ecb58ea9840dda1269b96cf87aef2"
          }
        },
        "1b5f377de16d44509926894aca7dd347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4cd6cb7dffc42b8b1a74b3be24b54f3",
            "placeholder": "​",
            "style": "IPY_MODEL_c09ce722f7eb494eac3ba59dc5f78e84",
            "value": "Generating embeddings: 100%"
          }
        },
        "298aaaa48ebe422c9f5b03a3a262d4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13765dc2f70849e6954c9ec0958a6d48",
            "max": 2048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23ffdd5d2a5040b99197b2b3373010c2",
            "value": 2048
          }
        },
        "85043ebd9a394ec6bac2d350574cd6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5cf72587f1e4dbdb5c3730a73043e90",
            "placeholder": "​",
            "style": "IPY_MODEL_9676f3b9ea704c71b3ca3f90b2c2277f",
            "value": " 2048/2048 [09:41&lt;00:00,  4.65it/s]"
          }
        },
        "d07ecb58ea9840dda1269b96cf87aef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4cd6cb7dffc42b8b1a74b3be24b54f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09ce722f7eb494eac3ba59dc5f78e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13765dc2f70849e6954c9ec0958a6d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ffdd5d2a5040b99197b2b3373010c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5cf72587f1e4dbdb5c3730a73043e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9676f3b9ea704c71b3ca3f90b2c2277f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3070780a5b004134b4a88dff471c1c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76319890348a4cdf88fe203a8201d598",
              "IPY_MODEL_ce9dea7568f54e6883fd0b76990a8d87",
              "IPY_MODEL_a6614169746c4524a42f8cfc48ebd9aa"
            ],
            "layout": "IPY_MODEL_afe23b68790b409c805126cae31b13fd"
          }
        },
        "76319890348a4cdf88fe203a8201d598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e7f7173c3a47b5ae5467d9b0f449a7",
            "placeholder": "​",
            "style": "IPY_MODEL_8fdcd734baa249118469ccb5f9ff1e38",
            "value": "Generating embeddings: 100%"
          }
        },
        "ce9dea7568f54e6883fd0b76990a8d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a2fe8bd57054e109c83bba7569ba037",
            "max": 1575,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1956e21304db4147ac112d7d456c6d73",
            "value": 1575
          }
        },
        "a6614169746c4524a42f8cfc48ebd9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8290fad23ba54d1b97ced391c55c92f7",
            "placeholder": "​",
            "style": "IPY_MODEL_28d3daaff5ee40caa9dfc7aa21c0ce1f",
            "value": " 1575/1575 [07:12&lt;00:00,  2.56it/s]"
          }
        },
        "afe23b68790b409c805126cae31b13fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e7f7173c3a47b5ae5467d9b0f449a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fdcd734baa249118469ccb5f9ff1e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a2fe8bd57054e109c83bba7569ba037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1956e21304db4147ac112d7d456c6d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8290fad23ba54d1b97ced391c55c92f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28d3daaff5ee40caa9dfc7aa21c0ce1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcYZ_CLNQjKg",
        "outputId": "5fe657e0-decd-4852-8606-c70bb8eb0171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "llama-index\n",
        "llama-index-llms-huggingface\n",
        "llama-index-embeddings-huggingface\n",
        "chromadb\n",
        "llama-index-vector-stores-chroma\n",
        "llama-index-llms-groq\n",
        "einops\n",
        "accelerate\n",
        "sentence-transformers\n",
        "llama-index-llms-mistralai\n",
        "llama-index-embeddings-mistralai\n",
        "chainlit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TL6x5KJFSEVI",
        "outputId": "d4a70aff-e1fe-4d2e-a4ab-53f5b157c5aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index (from -r requirements.txt (line 1))\n",
            "  Downloading llama_index-0.10.52-py3-none-any.whl (6.8 kB)\n",
            "Collecting llama-index-llms-huggingface (from -r requirements.txt (line 2))\n",
            "  Downloading llama_index_llms_huggingface-0.2.4-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-embeddings-huggingface (from -r requirements.txt (line 3))\n",
            "  Downloading llama_index_embeddings_huggingface-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting chromadb (from -r requirements.txt (line 4))\n",
            "  Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-vector-stores-chroma (from -r requirements.txt (line 5))\n",
            "  Downloading llama_index_vector_stores_chroma-0.1.10-py3-none-any.whl (5.0 kB)\n",
            "Collecting llama-index-llms-groq (from -r requirements.txt (line 6))\n",
            "  Downloading llama_index_llms_groq-0.1.4-py3-none-any.whl (2.9 kB)\n",
            "Collecting einops (from -r requirements.txt (line 7))\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r requirements.txt (line 8))\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers (from -r requirements.txt (line 9))\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-mistralai (from -r requirements.txt (line 10))\n",
            "  Downloading llama_index_llms_mistralai-0.1.17-py3-none-any.whl (5.6 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core==0.10.52.post1 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_core-0.10.52.post1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_llms_openai-0.1.25-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.7-py3-none-any.whl (5.9 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_readers_file-0.1.27-py3-none-any.whl (37 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cloud<0.0.7,>=0.0.6 (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_cloud-0.0.6-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (8.4.2)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface->-r requirements.txt (line 2)) (0.23.4)\n",
            "Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface->-r requirements.txt (line 2)) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers[torch]<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface->-r requirements.txt (line 2)) (4.41.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 4)) (2.8.0)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 4)) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 4)) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 4)) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb->-r requirements.txt (line 4))\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai-like<0.2.0,>=0.1.3 (from llama-index-llms-groq->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_llms_openai_like-0.1.3-py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 8)) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 8)) (0.4.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 9)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 9)) (1.11.4)\n",
            "Collecting mistralai>=0.4.0 (from llama-index-llms-mistralai->-r requirements.txt (line 10))\n",
            "  Downloading mistralai-0.4.2-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 4)) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 4)) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface->-r requirements.txt (line 2)) (3.15.4)\n",
            "Collecting minijinja>=1.0 (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Downloading minijinja-2.0.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (853 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.2/853.2 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1)) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading llama_parse-0.4.5-py3-none-any.whl (9.1 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (1.12.1)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4)) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 4)) (67.7.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 4)) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (3.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface->-r requirements.txt (line 2)) (2024.5.15)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1)) (2.5)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 4)) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1))\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.52.post1->llama-index->-r requirements.txt (line 1)) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=7659c2a5ba427c52febafd150463b9cc68e01347346a3a44dad9be19bfa9a1e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: striprtf, pypika, monotonic, mmh3, dirtyjson, websockets, uvloop, ujson, python-multipart, python-dotenv, pypdf, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, minijinja, marshmallow, importlib-metadata, humanfriendly, httptools, h11, einops, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, email_validator, coloredlogs, text-generation, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, nvidia-cusolver-cu12, kubernetes, httpx, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, mistralai, llama-cloud, fastapi-cli, sentence-transformers, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, llama-index-legacy, llama-index-core, fastapi, accelerate, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-mistralai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-huggingface, chromadb, llama-index-vector-stores-chroma, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-openai-like, llama-index-llms-huggingface, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-llms-groq, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed accelerate-0.32.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 dnspython-2.6.1 einops-0.8.0 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.1.0 kubernetes-30.1.0 llama-cloud-0.0.6 llama-index-0.10.52 llama-index-agent-openai-0.2.7 llama-index-cli-0.1.12 llama-index-core-0.10.52.post1 llama-index-embeddings-huggingface-0.2.2 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.2.3 llama-index-legacy-0.9.48 llama-index-llms-groq-0.1.4 llama-index-llms-huggingface-0.2.4 llama-index-llms-mistralai-0.1.17 llama-index-llms-openai-0.1.25 llama-index-llms-openai-like-0.1.3 llama-index-multi-modal-llms-openai-0.1.7 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.27 llama-index-readers-llama-parse-0.1.6 llama-index-vector-stores-chroma-0.1.10 llama-parse-0.4.5 marshmallow-3.21.3 minijinja-2.0.1 mistralai-0.4.2 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.18.1 openai-1.35.10 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.6 overrides-7.7.0 posthog-3.5.0 pypdf-4.2.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 sentence-transformers-3.0.1 starlette-0.37.2 striprtf-0.0.26 text-generation-0.7.0 tiktoken-0.7.0 typing-inspect-0.9.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4aiexSl6YLep",
        "outputId": "1ca62019-f9ec-4200-84ce-0dfbf4cc9842"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chainlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yh4rLQEAMyu_",
        "outputId": "bb50e02d-abf0-4c2b-a3a8-2012eb6b8069"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chainlit\n",
            "  Downloading chainlit-1.1.306-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0.0,>=23.1.0 (from chainlit)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting asyncer<0.0.3,>=0.0.2 (from chainlit)\n",
            "  Downloading asyncer-0.0.2-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from chainlit) (8.1.7)\n",
            "Collecting dataclasses_json<0.6.0,>=0.5.7 (from chainlit)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting fastapi<0.111.0,>=0.110.1 (from chainlit)\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype<2.0.0,>=1.2.0 (from chainlit)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from chainlit) (0.27.0)\n",
            "Collecting lazify<0.5.0,>=0.4.0 (from chainlit)\n",
            "  Downloading Lazify-0.4.0-py2.py3-none-any.whl (3.1 kB)\n",
            "Collecting literalai==0.0.607 (from chainlit)\n",
            "  Downloading literalai-0.0.607.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from chainlit) (1.6.0)\n",
            "Collecting numpy<2.0,>=1.26 (from chainlit)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.1 (from chainlit)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from chainlit) (2.8.0)\n",
            "Collecting pyjwt<3.0.0,>=2.8.0 (from chainlit)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from chainlit) (1.0.1)\n",
            "Requirement already satisfied: python-multipart<0.0.10,>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from chainlit) (0.0.9)\n",
            "Collecting python-socketio<6.0.0,>=5.11.0 (from chainlit)\n",
            "  Downloading python_socketio-5.11.3-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from chainlit) (0.37.2)\n",
            "Collecting syncer<3.0.0,>=2.0.3 (from chainlit)\n",
            "  Downloading syncer-2.0.3.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from chainlit) (2.0.1)\n",
            "Collecting uptrace<2.0.0,>=1.22.0 (from chainlit)\n",
            "  Downloading uptrace-1.24.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting uvicorn<0.26.0,>=0.25.0 (from chainlit)\n",
            "  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles<0.21.0,>=0.20.0 (from chainlit)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chevron>=0.14.0 (from literalai==0.0.607->chainlit)\n",
            "  Downloading chevron-0.14.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from asyncer<0.0.3,>=0.0.2->chainlit) (3.7.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses_json<0.6.0,>=0.5.7->chainlit) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses_json<0.6.0,>=0.5.7->chainlit) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.111.0,>=0.110.1->chainlit) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->chainlit) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->chainlit) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->chainlit) (2.20.0)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio<6.0.0,>=5.11.0->chainlit) (0.23.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio<6.0.0,>=5.11.0->chainlit)\n",
            "  Downloading python_engineio-4.9.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opentelemetry-api~=1.24 in /usr/local/lib/python3.10/dist-packages (from uptrace<2.0.0,>=1.22.0->chainlit) (1.25.0)\n",
            "Collecting opentelemetry-exporter-otlp~=1.24 (from uptrace<2.0.0,>=1.22.0->chainlit)\n",
            "  Downloading opentelemetry_exporter_otlp-1.25.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: opentelemetry-instrumentation~=0.45b0 in /usr/local/lib/python3.10/dist-packages (from uptrace<2.0.0,>=1.22.0->chainlit) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-sdk~=1.24 in /usr/local/lib/python3.10/dist-packages (from uptrace<2.0.0,>=1.22.0->chainlit) (1.25.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.4.0->asyncer<0.0.3,>=0.0.2->chainlit) (1.2.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (7.1.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (1.25.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.25.0 (from opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (1.63.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (1.64.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (1.25.0)\n",
            "Requirement already satisfied: requests~=2.7 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (2.31.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.25.0->opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation~=0.45b0->uptrace<2.0.0,>=1.22.0->chainlit) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation~=0.45b0->uptrace<2.0.0,>=1.22.0->chainlit) (1.14.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (0.46b0)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio<6.0.0,>=5.11.0->chainlit)\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses_json<0.6.0,>=0.5.7->chainlit) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (3.19.2)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio<6.0.0,>=5.11.0->chainlit)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.25.0->opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit) (2.0.7)\n",
            "Building wheels for collected packages: literalai, syncer\n",
            "  Building wheel for literalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for literalai: filename=literalai-0.0.607-py3-none-any.whl size=64143 sha256=dacb0ea30083e01bb729acfc56c5f1233bc2e315cbae900567072560bdf25e01\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/e9/96/826c366cb47a2d2b23265f59beb18f9d5635ab75185cff7a9e\n",
            "  Building wheel for syncer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syncer: filename=syncer-2.0.3-py2.py3-none-any.whl size=3436 sha256=4eafc0086fc287916bcf0d8c30a1e95fe90bf5a8a6e210180a3f7274de711a89\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/e4/36/bcaad665bcc2b672888ff2df1a5a1dc638378d8765055313cd\n",
            "Successfully built literalai syncer\n",
            "Installing collected packages: syncer, lazify, filetype, chevron, wsproto, uvicorn, pyjwt, packaging, numpy, aiofiles, watchfiles, simple-websocket, asyncer, python-engineio, literalai, fastapi, dataclasses_json, python-socketio, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp, uptrace, chainlit\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.30.1\n",
            "    Uninstalling uvicorn-0.30.1:\n",
            "      Successfully uninstalled uvicorn-0.30.1\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: watchfiles\n",
            "    Found existing installation: watchfiles 0.22.0\n",
            "    Uninstalling watchfiles-0.22.0:\n",
            "      Successfully uninstalled watchfiles-0.22.0\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.111.0\n",
            "    Uninstalling fastapi-0.111.0:\n",
            "      Successfully uninstalled fastapi-0.111.0\n",
            "  Attempting uninstall: dataclasses_json\n",
            "    Found existing installation: dataclasses-json 0.6.7\n",
            "    Uninstalling dataclasses-json-0.6.7:\n",
            "      Successfully uninstalled dataclasses-json-0.6.7\n",
            "Successfully installed aiofiles-23.2.1 asyncer-0.0.2 chainlit-1.1.306 chevron-0.14.0 dataclasses_json-0.5.14 fastapi-0.110.3 filetype-1.2.0 lazify-0.4.0 literalai-0.0.607 numpy-1.26.4 opentelemetry-exporter-otlp-1.25.0 opentelemetry-exporter-otlp-proto-http-1.25.0 packaging-23.2 pyjwt-2.8.0 python-engineio-4.9.1 python-socketio-5.11.3 simple-websocket-1.0.0 syncer-2.0.3 uptrace-1.24.0 uvicorn-0.25.0 watchfiles-0.20.0 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader,VectorStoreIndex,SummaryIndex\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.tools import FunctionTool,QueryEngineTool\n",
        "from llama_index.core.vector_stores import MetadataFilters,FilterCondition\n",
        "from typing import List,Optional"
      ],
      "metadata": {
        "id": "mCKVMjvuSGQb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define embedding model and LLM\n"
      ],
      "metadata": {
        "id": "i_DZGD2HeIIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "#from llama_index.core import Settings\n",
        "from llama_index.llms.mistralai import MistralAI\n",
        "from llama_index.embeddings.mistralai import MistralAIEmbedding\n",
        "\n",
        "config_data = json.load(open(\"config.json\"))\n",
        "HF_TOKEN = config_data[\"HF_TOKEN\"]\n",
        "embed_model = MistralAIEmbedding(model_name=\"mistral-embed\", api_key=\"H1rVHKqTjonaHi4vOZ8jozgwtrhRiSjZ\")\n",
        "\n",
        "llm = MistralAI(model = 'mistral-large-latest', api_key = \"H1rVHKqTjonaHi4vOZ8jozgwtrhRiSjZ\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OuUXOV7vT2d3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read file"
      ],
      "metadata": {
        "id": "L_mNYSyYeNAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(input_files=['Harry Potter The Complete Collection.pdf']).load_data(num_workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMdSKjJ1XkZC",
        "outputId": "281a744d-f405-45ef-d6b3-aeddd629dc54"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/llama_index/core/readers/file/base.py:663: UserWarning: Specified num_workers exceed number of CPUs in the system. Setting `num_workers` down to the maximum CPU count.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chunk the document"
      ],
      "metadata": {
        "id": "pZLG3U8nePUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = SentenceSplitter(chunk_size=1024,chunk_overlap=100)\n",
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "print(f\"Length of nodes : {len(nodes)}\")\n",
        "print(f\"get the content for node 0 :{nodes[0].get_content(metadata_mode='all')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBMuh90rdObS",
        "outputId": "31152ae8-df04-4ca1-92e2-01e734c4f25c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of nodes : 3623\n",
            "get the content for node 0 :page_label: 1\n",
            "file_name: Harry Potter The Complete Collection.pdf\n",
            "file_path: Harry Potter The Complete Collection.pdf\n",
            "file_type: application/pdf\n",
            "file_size: 17338552\n",
            "creation_date: 2024-07-07\n",
            "last_modified_date: 2024-07-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define relevant contexts\n"
      ],
      "metadata": {
        "id": "eshwoUAFJNjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import ServiceContext, StorageContext\n",
        "\n",
        "service_context = ServiceContext.from_defaults(llm = llm,\n",
        "                                               embed_model = embed_model)\n",
        "                                               #callback_manager = CallbackManager([cl.LlamaIndexCallbackHandler()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHu-oPl7JMk8",
        "outputId": "7563d843-73ee-4d4b-e671-6c9db9ee52f6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-fb749a54b22e>:3: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(llm = llm,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create vector store index\n"
      ],
      "metadata": {
        "id": "C6XKMf8aeZOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index = VectorStoreIndex.from_documents(documents,\n",
        "                                               #storage_context=storage_context\n",
        "                                               service_context=service_context,\n",
        "                                               node_parser=nodes,\n",
        "                                               show_progress=True)\n",
        "\n",
        "vector_index.storage_context.persist(persist_dir=\"./storage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c6a827997067416e84c5b798322d30cc",
            "79051322fd6c4ed98ebc0497d2cb12bf",
            "a8b7454b99304e8093d25b85ce480f2b",
            "6e16c29d053d4c2195d5303f85336101",
            "1153df1c0a024464bbf1fa898bad171c",
            "c6d0af4c0eda47deacea6cf42441a3d6",
            "7ee03dca708f4c05b70031d4a401eb4e",
            "4bbc68f78dc740c7a5ddc2dfb707839f",
            "a782496d1210484a8c631cafe12c1574",
            "987098d8472b4932968af544b21918d1",
            "8027d8d135924145893ff391c3d8aba2",
            "caa17dc1f5b54fe59b1364b222668f0f",
            "1b5f377de16d44509926894aca7dd347",
            "298aaaa48ebe422c9f5b03a3a262d4f9",
            "85043ebd9a394ec6bac2d350574cd6c8",
            "d07ecb58ea9840dda1269b96cf87aef2",
            "d4cd6cb7dffc42b8b1a74b3be24b54f3",
            "c09ce722f7eb494eac3ba59dc5f78e84",
            "13765dc2f70849e6954c9ec0958a6d48",
            "23ffdd5d2a5040b99197b2b3373010c2",
            "d5cf72587f1e4dbdb5c3730a73043e90",
            "9676f3b9ea704c71b3ca3f90b2c2277f",
            "3070780a5b004134b4a88dff471c1c03",
            "76319890348a4cdf88fe203a8201d598",
            "ce9dea7568f54e6883fd0b76990a8d87",
            "a6614169746c4524a42f8cfc48ebd9aa",
            "afe23b68790b409c805126cae31b13fd",
            "c2e7f7173c3a47b5ae5467d9b0f449a7",
            "8fdcd734baa249118469ccb5f9ff1e38",
            "3a2fe8bd57054e109c83bba7569ba037",
            "1956e21304db4147ac112d7d456c6d73",
            "8290fad23ba54d1b97ced391c55c92f7",
            "28d3daaff5ee40caa9dfc7aa21c0ce1f"
          ]
        },
        "id": "gcktgmrgebDz",
        "outputId": "04b45d7e-c098-4171-a07d-cd64416d2ed8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/3623 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6a827997067416e84c5b798322d30cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "caa17dc1f5b54fe59b1364b222668f0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/1575 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3070780a5b004134b4a88dff471c1c03"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create the query engine (for running on CLI)"
      ],
      "metadata": {
        "id": "NARgjSGILd4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(similarity_top_k = 3,\n",
        "                                            service_context=service_context)\n",
        "\n",
        "response = query_engine.query(\"Who is the main character?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D--KhSivJ4qr",
        "outputId": "ba2b02b7-0e30-4134-9f93-889047a1cb2d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The main character is a boy named Harry Potter, although he is not directly mentioned in the provided context. The context refers to the Dursleys, who have a secret related to the Potters, and it is mentioned that the Potters have a small son. The file path \"Harry Potter The Complete Collection.pdf\" also suggests that the main character is Harry Potter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deploy the engine on Chainlit"
      ],
      "metadata": {
        "id": "A2lqSIUBNjNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from llama_index.core.callbacks.base import CallbackManager\n",
        "from llama_index.core import load_index_from_storage, StorageContext, ServiceContext\n",
        "from llama_index.llms.mistralai import MistralAI\n",
        "from llama_index.embeddings.mistralai import MistralAIEmbedding\n",
        "import chainlit as cl\n",
        "\n",
        "@cl.on_chat_start\n",
        "async def start_chat():\n",
        "  embed_model = MistralAIEmbedding(model_name=\"mistral-embed\", api_key=\"H1rVHKqTjonaHi4vOZ8jozgwtrhRiSjZ\")\n",
        "\n",
        "  llm = MistralAI(model = 'mistral-large-latest', api_key = \"H1rVHKqTjonaHi4vOZ8jozgwtrhRiSjZ\")\n",
        "  storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "\n",
        "  service_context = ServiceContext.from_defaults(llm = llm,\n",
        "                                                 embed_model = embed_model,\n",
        "                                                 callback_manager = CallbackManager([cl.LlamaIndexCallbackHandler()]))\n",
        "\n",
        "  index = load_index_from_storage(\n",
        "      service_context = service_context,\n",
        "      storage_context = storage_context,\n",
        "  )\n",
        "\n",
        "  query_engine = index.as_query_engine(similarity_top_k = 3,\n",
        "                                       service_context = service_context)\n",
        "\n",
        "  cl.user_session.set(\"chatbot\", query_engine)\n",
        "\n",
        "  await cl.Message(\n",
        "      author=\"Assistant\", content=\"Hello! What do you want to know about Harry Potter?\"\n",
        "  ).send()\n",
        "\n",
        "@cl.on_message\n",
        "async def main(message: cl.Message):\n",
        "  query_engine = cl.user_session.get(\"chatbot\")\n",
        "\n",
        "  response = await cl.make_async(query_engine.query)(message.content)\n",
        "\n",
        "  response_message = cl.Message(content=\"\", author=\"Assistant\")\n",
        "\n",
        "  for token in response.response:\n",
        "    await response_message.stream_token(token=token)\n",
        "\n",
        "  await response_message.send()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvP-iE54NFv7",
        "outputId": "435ce378-2881-464d-804b-b0e30b26061c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fuser -n tcp -k 8000\n",
        "\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(8000)\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-E50xSnmQ7NS",
        "outputId": "11e5d119-610e-4bfc-cdec-7b5a916f457e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://z9ohyrwfn0d-496ff2e9c6d22116-8000-colab.googleusercontent.com/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chainlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "poosod0BRZvT",
        "outputId": "c415d536-5119-4a74-9f76-ba742ed0914f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-07 18:19:26 - Your app is available at http://localhost:8000\n",
            "2024-07-07 18:19:32 - Translated markdown file for en-US not found. Defaulting to chainlit.md.\n",
            "2024-07-07 18:20:21 - Loading all indices.\n",
            "2024-07-07 18:20:21 - HTTP Request: POST https://api.mistral.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2024-07-07 18:20:21 - Task exception was never retrieved\n",
            "future: <Task finished name='Task-60' coro=<Step.update() done, defined at /usr/local/lib/python3.10/dist-packages/chainlit/step.py:275> exception=TypeError(\"unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
            "    result = coro.throw(exc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/step.py\", line 296, in update\n",
            "    await asyncio.gather(*tasks)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 184, in send\n",
            "    await self._create()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 149, in _create\n",
            "    file_dict = await context.session.persist_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 117, in persist_file\n",
            "    self.files_dir.mkdir(exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 103, in files_dir\n",
            "    return FILES_DIRECTORY / self.id\n",
            "TypeError: unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\n",
            "2024-07-07 18:20:21 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2024-07-07 18:20:26 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2024-07-07 18:20:26 - Task exception was never retrieved\n",
            "future: <Task finished name='Task-85' coro=<Step.update() done, defined at /usr/local/lib/python3.10/dist-packages/chainlit/step.py:275> exception=TypeError(\"unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
            "    result = coro.throw(exc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/step.py\", line 296, in update\n",
            "    await asyncio.gather(*tasks)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 184, in send\n",
            "    await self._create()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 149, in _create\n",
            "    file_dict = await context.session.persist_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 117, in persist_file\n",
            "    self.files_dir.mkdir(exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 103, in files_dir\n",
            "    return FILES_DIRECTORY / self.id\n",
            "TypeError: unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\n",
            "2024-07-07 18:20:47 - HTTP Request: POST https://api.mistral.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2024-07-07 18:20:48 - Task exception was never retrieved\n",
            "future: <Task finished name='Task-230' coro=<Step.update() done, defined at /usr/local/lib/python3.10/dist-packages/chainlit/step.py:275> exception=TypeError(\"unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
            "    result = coro.throw(exc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/step.py\", line 296, in update\n",
            "    await asyncio.gather(*tasks)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 184, in send\n",
            "    await self._create()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 149, in _create\n",
            "    file_dict = await context.session.persist_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 117, in persist_file\n",
            "    self.files_dir.mkdir(exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 103, in files_dir\n",
            "    return FILES_DIRECTORY / self.id\n",
            "TypeError: unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\n",
            "2024-07-07 18:20:49 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2024-07-07 18:20:49 - Task exception was never retrieved\n",
            "future: <Task finished name='Task-240' coro=<Step.update() done, defined at /usr/local/lib/python3.10/dist-packages/chainlit/step.py:275> exception=TypeError(\"unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
            "    result = coro.throw(exc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/step.py\", line 296, in update\n",
            "    await asyncio.gather(*tasks)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 184, in send\n",
            "    await self._create()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 149, in _create\n",
            "    file_dict = await context.session.persist_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 117, in persist_file\n",
            "    self.files_dir.mkdir(exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 103, in files_dir\n",
            "    return FILES_DIRECTORY / self.id\n",
            "TypeError: unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\n",
            "2024-07-07 18:20:55 - HTTP Request: POST https://api.mistral.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2024-07-07 18:20:55 - Task exception was never retrieved\n",
            "future: <Task finished name='Task-325' coro=<Step.update() done, defined at /usr/local/lib/python3.10/dist-packages/chainlit/step.py:275> exception=TypeError(\"unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
            "    result = coro.throw(exc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/step.py\", line 296, in update\n",
            "    await asyncio.gather(*tasks)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 184, in send\n",
            "    await self._create()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 149, in _create\n",
            "    file_dict = await context.session.persist_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 117, in persist_file\n",
            "    self.files_dir.mkdir(exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 103, in files_dir\n",
            "    return FILES_DIRECTORY / self.id\n",
            "TypeError: unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\n",
            "2024-07-07 18:20:58 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2024-07-07 18:20:58 - Task exception was never retrieved\n",
            "future: <Task finished name='Task-335' coro=<Step.update() done, defined at /usr/local/lib/python3.10/dist-packages/chainlit/step.py:275> exception=TypeError(\"unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
            "    result = coro.throw(exc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/step.py\", line 296, in update\n",
            "    await asyncio.gather(*tasks)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 184, in send\n",
            "    await self._create()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 149, in _create\n",
            "    file_dict = await context.session.persist_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 117, in persist_file\n",
            "    self.files_dir.mkdir(exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 103, in files_dir\n",
            "    return FILES_DIRECTORY / self.id\n",
            "TypeError: unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\n",
            "2024-07-07 18:21:18 - HTTP Request: POST https://api.mistral.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2024-07-07 18:21:19 - Task exception was never retrieved\n",
            "future: <Task finished name='Task-778' coro=<Step.update() done, defined at /usr/local/lib/python3.10/dist-packages/chainlit/step.py:275> exception=TypeError(\"unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
            "    result = coro.throw(exc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/step.py\", line 296, in update\n",
            "    await asyncio.gather(*tasks)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 184, in send\n",
            "    await self._create()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 149, in _create\n",
            "    file_dict = await context.session.persist_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 117, in persist_file\n",
            "    self.files_dir.mkdir(exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 103, in files_dir\n",
            "    return FILES_DIRECTORY / self.id\n",
            "TypeError: unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\n",
            "2024-07-07 18:21:24 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2024-07-07 18:21:24 - Task exception was never retrieved\n",
            "future: <Task finished name='Task-792' coro=<Step.update() done, defined at /usr/local/lib/python3.10/dist-packages/chainlit/step.py:275> exception=TypeError(\"unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 234, in __step\n",
            "    result = coro.throw(exc)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/step.py\", line 296, in update\n",
            "    await asyncio.gather(*tasks)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 184, in send\n",
            "    await self._create()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/element.py\", line 149, in _create\n",
            "    file_dict = await context.session.persist_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 117, in persist_file\n",
            "    self.files_dir.mkdir(exist_ok=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/chainlit/session.py\", line 103, in files_dir\n",
            "    return FILES_DIRECTORY / self.id\n",
            "TypeError: unsupported operand type(s) for /: 'PosixPath' and 'NoneType'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLqDIt5kRbSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}